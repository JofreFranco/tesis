{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38764bitpyenv389060af4eb43a4d22820780620fff68d6",
   "display_name": "Python 3.8.7 64-bit ('.PyEnv38')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Prepocesamiento y preparación del dataset.\n",
    "\n",
    "En primer lugar los audios se convierten a formato mp3 para que estén igual a las grabaciones del call center. Después se aplica un filtro de 300 a 3300 Hz porque es el rango de frecuencias en el que trabajan los codecs de audio más utilizados para telefonía IP. Por último, a los audios se les calcula el los features.\n",
    "Los casos positivos se incrementan agregando ruido y desplazándolos en tiempo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from database import Database\n",
    "from audio_process import butter_bandpass_filter, feature_extraction, augment_data\n",
    "\n"
   ]
  },
  {
   "source": [
    "#### Armado del dataset completo\n",
    "\n",
    "- Se eliminan los audios de menos de 1 segundo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_dataset(directory, name, n_mfcc, n_start, augment=True ):\n",
    "    db = Database(\"Dataset_bruto\")\n",
    "    f0min = 300\n",
    "    f0max = 3300\n",
    "    directory = directory + '*.mp3'\n",
    "    print(directory)\n",
    "    files = glob.glob(directory)\n",
    "    anger = 0\n",
    "    files = files[n_start :]\n",
    "    try:\n",
    "        for n, path in enumerate(files):\n",
    "            if n % 1000 == 0:\n",
    "                print(n)\n",
    "\n",
    "            file_name = os.path.basename(path)\n",
    "            file_name = file_name.replace(\"-\", \"_\")\n",
    "            in_db = db.select_by_id(file_name, like=True)\n",
    "            if in_db:\n",
    "                continue\n",
    "            emotion = file_name.split('_')[2]\n",
    "            file_name = f'{name}_{file_name}'\n",
    "            if emotion == '05' or emotion == 'anger.mp3' or emotion =='ANG':\n",
    "                emotion = 1\n",
    "                anger = anger + 1\n",
    "            else:\n",
    "                emotion = 0\n",
    "            \n",
    "            audio, sr = librosa.load_mp3(path)\n",
    "            if len(list(audio))/sr < 0.5:\n",
    "                    continue\n",
    "            features = feature_extraction(audio, sr, f0min, f0max, n_mfcc, unit=\"Hertz\" )\n",
    "            if features != 'skip':\n",
    "                 db.post(file_name, emotion, features, augmentation='')\n",
    "            names = ['clipping', 'time_stretch', 'pitch_shift', 'reverb']\n",
    "            augmented_audios = augment_data(audio, sr)\n",
    "            for audio, aug in zip(augmented_audios, names):\n",
    "                features = feature_extraction(audio, sr, f0min, f0max, n_mfcc, unit=\"Hertz\" )\n",
    "                if features != 'skip':\n",
    "                    db.post(file_name, emotion, features, augmentation=aug)\n",
    "                else:\n",
    "                    print(features)\n",
    "    except Exception as e:\n",
    "        print(path)\n",
    "        raise(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/francoj/Documentos/Reconocimiento de emociones/tesis/Data/Meld/*/*.mp3\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "/home/francoj/Documentos/Reconocimiento de emociones/tesis/Data/Enterface/*/*.mp3\n",
      "0\n",
      "1000\n",
      "/home/francoj/Documentos/Reconocimiento de emociones/tesis/Data/CREMA-D/*.mp3\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "/home/francoj/Documentos/Reconocimiento de emociones/tesis/Data/IEMOCAP/*.mp3\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "Meld = \"Data/Meld/*/\"\n",
    "Enterface = \"Data/Enterface/*/\"\n",
    "Crema = \"Data/CREMA-D/\"\n",
    "IEMOCAP = \"Data/IEMOCAP/\"\n",
    "datasets= [Meld, Enterface, Crema, IEMOCAP]\n",
    "names = ['Meld', 'Enterface', 'Crema', 'IEMOCAP']\n",
    "\n",
    "for name, dataset_directory in zip(names, datasets):\n",
    "    process_dataset(dataset_directory, name, 16, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database(\"Dataset_bruto\")\n",
    "rgx = re.compile(\"Enterface_.._.._05.*\")\n",
    "result = db.collection.find({\"_id\": rgx})\n",
    "for r in result:\n",
    "    id = r[\"_id\"]\n",
    "    r[\"label\"] = 1\n",
    "    db.collection.update_one({\"_id\": id}, {\"$set\": r})\n",
    "rgx = re.compile(\"Enterface.*\")\n",
    "result = db.collection.find({\"_id\": rgx, \"label\": 1})\n",
    "print(len(list(result)))\n",
    "\n",
    "rgx = re.compile(\"Meld_.*_anger.*\")\n",
    "result = db.collection.find({\"_id\": rgx})\n",
    "for r in result:\n",
    "    id = r[\"_id\"]\n",
    "    r[\"label\"] = 1\n",
    "    db.collection.update_one({\"_id\": id}, {\"$set\": r})\n",
    "rgx = re.compile(\"Meld.*\")\n",
    "result = db.collection.find({\"_id\": rgx, \"label\": 1})\n",
    "print(len(list(result)))\n",
    "\n",
    "rgx = re.compile(\"Crema_.*_ANG.*\")\n",
    "result = db.collection.find({\"_id\": rgx})\n",
    "for r in result:\n",
    "    id = r[\"_id\"]\n",
    "    r[\"label\"] = 1\n",
    "    db.collection.update_one({\"_id\": id}, {\"$set\": r})\n",
    "rgx = re.compile(\"Crema.*\")\n",
    "result = db.collection.find({\"_id\": rgx, \"label\": 1})\n",
    "print(len(list(result)))\n",
    "\n",
    "rgx = re.compile(\"IEMOCAP_.*_ang.*\")\n",
    "result = db.collection.find({\"_id\": rgx})\n",
    "for r in result:\n",
    "    id = r[\"_id\"]\n",
    "    r[\"label\"] = 1\n",
    "    db.collection.update_one({\"_id\": id}, {\"$set\": r})\n",
    "rgx = re.compile(\"IEMOCAP.*\")\n",
    "result = db.collection.find({\"_id\": rgx, \"label\": 1})\n",
    "print(len(list(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [{field: np.nan} for field in db.feature_names]\n",
    "r = {\"$or\": l}\n",
    "db.collection.delete_many(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgx = re.compile(\".*xxx.*\")\n",
    "db.collection.delete_many({\"_id\": rgx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(db.collection.find({\"augmented\": False}))\n",
    "n = int(len(results) * 0.4)\n",
    "n_sample = n if n % 2 == 0 else n - 1\n",
    "\n",
    "test_val = np.random.choice(results, n_sample, False)\n",
    "\n",
    "test = list(test_val[0 : int(len(test_val) / 2)])\n",
    "val = list(test_val[int(len(test_val) / 2) :])\n",
    "db_val = Database(\"Dataset_validation\")\n",
    "db_test = Database(\"Dataset_test\")\n",
    "db_val.collection.insert_many(val)\n",
    "db_test.collection.insert_many(test)"
   ]
  }
 ]
}